{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5514f19c",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bff4ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "### MUST SET YOUR OWN OPENAI API KEY HERE\n",
    "os.environ[\"OPENAI_API_KEY\"] = '...'\n",
    "os.environ[\"ANTHROPIC_API_KEY\"] = '...'\n",
    "os.environ['MISTRAL_API_KEY'] = '...'\n",
    "os.environ[\"LLMANA_API_KEY\"] ='...'\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import random\n",
    "import re\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import time\n",
    "from tqdm import tqdm \n",
    "from model_api_client import ModelAPIClient\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "587708f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: litellm in /Users/katelee2389/Documents/ResearchS25/HypotheSAEs/hypothesaes/lib/python3.13/site-packages (1.74.0.post1)\n",
      "Requirement already satisfied: aiohttp>=3.10 in /Users/katelee2389/Documents/ResearchS25/HypotheSAEs/hypothesaes/lib/python3.13/site-packages (from litellm) (3.12.13)\n",
      "Requirement already satisfied: click in /Users/katelee2389/Documents/ResearchS25/HypotheSAEs/hypothesaes/lib/python3.13/site-packages (from litellm) (8.2.1)\n",
      "Requirement already satisfied: httpx>=0.23.0 in /Users/katelee2389/Documents/ResearchS25/HypotheSAEs/hypothesaes/lib/python3.13/site-packages (from litellm) (0.28.1)\n",
      "Requirement already satisfied: importlib-metadata>=6.8.0 in /Users/katelee2389/Documents/ResearchS25/HypotheSAEs/hypothesaes/lib/python3.13/site-packages (from litellm) (8.7.0)\n",
      "Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in /Users/katelee2389/Documents/ResearchS25/HypotheSAEs/hypothesaes/lib/python3.13/site-packages (from litellm) (3.1.6)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.22.0 in /Users/katelee2389/Documents/ResearchS25/HypotheSAEs/hypothesaes/lib/python3.13/site-packages (from litellm) (4.24.0)\n",
      "Requirement already satisfied: openai>=1.68.2 in /Users/katelee2389/Documents/ResearchS25/HypotheSAEs/hypothesaes/lib/python3.13/site-packages (from litellm) (1.86.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.5.0 in /Users/katelee2389/Documents/ResearchS25/HypotheSAEs/hypothesaes/lib/python3.13/site-packages (from litellm) (2.11.5)\n",
      "Requirement already satisfied: python-dotenv>=0.2.0 in /Users/katelee2389/Documents/ResearchS25/HypotheSAEs/hypothesaes/lib/python3.13/site-packages (from litellm) (1.1.1)\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in /Users/katelee2389/Documents/ResearchS25/HypotheSAEs/hypothesaes/lib/python3.13/site-packages (from litellm) (0.9.0)\n",
      "Requirement already satisfied: tokenizers in /Users/katelee2389/Documents/ResearchS25/HypotheSAEs/hypothesaes/lib/python3.13/site-packages (from litellm) (0.21.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /Users/katelee2389/Documents/ResearchS25/HypotheSAEs/hypothesaes/lib/python3.13/site-packages (from aiohttp>=3.10->litellm) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/katelee2389/Documents/ResearchS25/HypotheSAEs/hypothesaes/lib/python3.13/site-packages (from aiohttp>=3.10->litellm) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/katelee2389/Documents/ResearchS25/HypotheSAEs/hypothesaes/lib/python3.13/site-packages (from aiohttp>=3.10->litellm) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/katelee2389/Documents/ResearchS25/HypotheSAEs/hypothesaes/lib/python3.13/site-packages (from aiohttp>=3.10->litellm) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/katelee2389/Documents/ResearchS25/HypotheSAEs/hypothesaes/lib/python3.13/site-packages (from aiohttp>=3.10->litellm) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/katelee2389/Documents/ResearchS25/HypotheSAEs/hypothesaes/lib/python3.13/site-packages (from aiohttp>=3.10->litellm) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/katelee2389/Documents/ResearchS25/HypotheSAEs/hypothesaes/lib/python3.13/site-packages (from aiohttp>=3.10->litellm) (1.20.1)\n",
      "Requirement already satisfied: anyio in /Users/katelee2389/Documents/ResearchS25/HypotheSAEs/hypothesaes/lib/python3.13/site-packages (from httpx>=0.23.0->litellm) (4.9.0)\n",
      "Requirement already satisfied: certifi in /Users/katelee2389/Documents/ResearchS25/HypotheSAEs/hypothesaes/lib/python3.13/site-packages (from httpx>=0.23.0->litellm) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/katelee2389/Documents/ResearchS25/HypotheSAEs/hypothesaes/lib/python3.13/site-packages (from httpx>=0.23.0->litellm) (1.0.9)\n",
      "Requirement already satisfied: idna in /Users/katelee2389/Documents/ResearchS25/HypotheSAEs/hypothesaes/lib/python3.13/site-packages (from httpx>=0.23.0->litellm) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/katelee2389/Documents/ResearchS25/HypotheSAEs/hypothesaes/lib/python3.13/site-packages (from httpcore==1.*->httpx>=0.23.0->litellm) (0.16.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /Users/katelee2389/Documents/ResearchS25/HypotheSAEs/hypothesaes/lib/python3.13/site-packages (from importlib-metadata>=6.8.0->litellm) (3.23.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/katelee2389/Documents/ResearchS25/HypotheSAEs/hypothesaes/lib/python3.13/site-packages (from jinja2<4.0.0,>=3.1.2->litellm) (3.0.2)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Users/katelee2389/Documents/ResearchS25/HypotheSAEs/hypothesaes/lib/python3.13/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /Users/katelee2389/Documents/ResearchS25/HypotheSAEs/hypothesaes/lib/python3.13/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /Users/katelee2389/Documents/ResearchS25/HypotheSAEs/hypothesaes/lib/python3.13/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm) (0.25.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/katelee2389/Documents/ResearchS25/HypotheSAEs/hypothesaes/lib/python3.13/site-packages (from openai>=1.68.2->litellm) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/katelee2389/Documents/ResearchS25/HypotheSAEs/hypothesaes/lib/python3.13/site-packages (from openai>=1.68.2->litellm) (0.10.0)\n",
      "Requirement already satisfied: sniffio in /Users/katelee2389/Documents/ResearchS25/HypotheSAEs/hypothesaes/lib/python3.13/site-packages (from openai>=1.68.2->litellm) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /Users/katelee2389/Documents/ResearchS25/HypotheSAEs/hypothesaes/lib/python3.13/site-packages (from openai>=1.68.2->litellm) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /Users/katelee2389/Documents/ResearchS25/HypotheSAEs/hypothesaes/lib/python3.13/site-packages (from openai>=1.68.2->litellm) (4.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/katelee2389/Documents/ResearchS25/HypotheSAEs/hypothesaes/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.5.0->litellm) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/katelee2389/Documents/ResearchS25/HypotheSAEs/hypothesaes/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.5.0->litellm) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/katelee2389/Documents/ResearchS25/HypotheSAEs/hypothesaes/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.5.0->litellm) (0.4.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/katelee2389/Documents/ResearchS25/HypotheSAEs/hypothesaes/lib/python3.13/site-packages (from tiktoken>=0.7.0->litellm) (2024.11.6)\n",
      "Requirement already satisfied: requests>=2.26.0 in /Users/katelee2389/Documents/ResearchS25/HypotheSAEs/hypothesaes/lib/python3.13/site-packages (from tiktoken>=0.7.0->litellm) (2.32.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /Users/katelee2389/Documents/ResearchS25/HypotheSAEs/hypothesaes/lib/python3.13/site-packages (from tokenizers->litellm) (0.32.6)\n",
      "Requirement already satisfied: filelock in /Users/katelee2389/Documents/ResearchS25/HypotheSAEs/hypothesaes/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/katelee2389/Documents/ResearchS25/HypotheSAEs/hypothesaes/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm) (2025.5.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/katelee2389/Documents/ResearchS25/HypotheSAEs/hypothesaes/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/katelee2389/Documents/ResearchS25/HypotheSAEs/hypothesaes/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm) (6.0.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /Users/katelee2389/Documents/ResearchS25/HypotheSAEs/hypothesaes/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm) (1.1.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/katelee2389/Documents/ResearchS25/HypotheSAEs/hypothesaes/lib/python3.13/site-packages (from requests>=2.26.0->tiktoken>=0.7.0->litellm) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/katelee2389/Documents/ResearchS25/HypotheSAEs/hypothesaes/lib/python3.13/site-packages (from requests>=2.26.0->tiktoken>=0.7.0->litellm) (2.4.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: mistralai in /Users/katelee2389/Documents/ResearchS25/HypotheSAEs/hypothesaes/lib/python3.13/site-packages (1.9.1)\n",
      "Requirement already satisfied: eval-type-backport>=0.2.0 in /Users/katelee2389/Documents/ResearchS25/HypotheSAEs/hypothesaes/lib/python3.13/site-packages (from mistralai) (0.2.2)\n",
      "Requirement already satisfied: httpx>=0.28.1 in /Users/katelee2389/Documents/ResearchS25/HypotheSAEs/hypothesaes/lib/python3.13/site-packages (from mistralai) (0.28.1)\n",
      "Requirement already satisfied: pydantic>=2.10.3 in /Users/katelee2389/Documents/ResearchS25/HypotheSAEs/hypothesaes/lib/python3.13/site-packages (from mistralai) (2.11.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/katelee2389/Documents/ResearchS25/HypotheSAEs/hypothesaes/lib/python3.13/site-packages (from mistralai) (2.9.0.post0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/katelee2389/Documents/ResearchS25/HypotheSAEs/hypothesaes/lib/python3.13/site-packages (from mistralai) (0.4.1)\n",
      "Requirement already satisfied: anyio in /Users/katelee2389/Documents/ResearchS25/HypotheSAEs/hypothesaes/lib/python3.13/site-packages (from httpx>=0.28.1->mistralai) (4.9.0)\n",
      "Requirement already satisfied: certifi in /Users/katelee2389/Documents/ResearchS25/HypotheSAEs/hypothesaes/lib/python3.13/site-packages (from httpx>=0.28.1->mistralai) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/katelee2389/Documents/ResearchS25/HypotheSAEs/hypothesaes/lib/python3.13/site-packages (from httpx>=0.28.1->mistralai) (1.0.9)\n",
      "Requirement already satisfied: idna in /Users/katelee2389/Documents/ResearchS25/HypotheSAEs/hypothesaes/lib/python3.13/site-packages (from httpx>=0.28.1->mistralai) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/katelee2389/Documents/ResearchS25/HypotheSAEs/hypothesaes/lib/python3.13/site-packages (from httpcore==1.*->httpx>=0.28.1->mistralai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/katelee2389/Documents/ResearchS25/HypotheSAEs/hypothesaes/lib/python3.13/site-packages (from pydantic>=2.10.3->mistralai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/katelee2389/Documents/ResearchS25/HypotheSAEs/hypothesaes/lib/python3.13/site-packages (from pydantic>=2.10.3->mistralai) (2.33.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /Users/katelee2389/Documents/ResearchS25/HypotheSAEs/hypothesaes/lib/python3.13/site-packages (from pydantic>=2.10.3->mistralai) (4.14.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/katelee2389/Documents/ResearchS25/HypotheSAEs/hypothesaes/lib/python3.13/site-packages (from python-dateutil>=2.8.2->mistralai) (1.17.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/katelee2389/Documents/ResearchS25/HypotheSAEs/hypothesaes/lib/python3.13/site-packages (from anyio->httpx>=0.28.1->mistralai) (1.3.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: anthropic in /Users/katelee2389/Documents/ResearchS25/HypotheSAEs/hypothesaes/lib/python3.13/site-packages (0.57.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/katelee2389/Documents/ResearchS25/HypotheSAEs/hypothesaes/lib/python3.13/site-packages (from anthropic) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/katelee2389/Documents/ResearchS25/HypotheSAEs/hypothesaes/lib/python3.13/site-packages (from anthropic) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.25.0 in /Users/katelee2389/Documents/ResearchS25/HypotheSAEs/hypothesaes/lib/python3.13/site-packages (from anthropic) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/katelee2389/Documents/ResearchS25/HypotheSAEs/hypothesaes/lib/python3.13/site-packages (from anthropic) (0.10.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/katelee2389/Documents/ResearchS25/HypotheSAEs/hypothesaes/lib/python3.13/site-packages (from anthropic) (2.11.5)\n",
      "Requirement already satisfied: sniffio in /Users/katelee2389/Documents/ResearchS25/HypotheSAEs/hypothesaes/lib/python3.13/site-packages (from anthropic) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.10 in /Users/katelee2389/Documents/ResearchS25/HypotheSAEs/hypothesaes/lib/python3.13/site-packages (from anthropic) (4.14.0)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/katelee2389/Documents/ResearchS25/HypotheSAEs/hypothesaes/lib/python3.13/site-packages (from anyio<5,>=3.5.0->anthropic) (3.10)\n",
      "Requirement already satisfied: certifi in /Users/katelee2389/Documents/ResearchS25/HypotheSAEs/hypothesaes/lib/python3.13/site-packages (from httpx<1,>=0.25.0->anthropic) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/katelee2389/Documents/ResearchS25/HypotheSAEs/hypothesaes/lib/python3.13/site-packages (from httpx<1,>=0.25.0->anthropic) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/katelee2389/Documents/ResearchS25/HypotheSAEs/hypothesaes/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.25.0->anthropic) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/katelee2389/Documents/ResearchS25/HypotheSAEs/hypothesaes/lib/python3.13/site-packages (from pydantic<3,>=1.9.0->anthropic) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/katelee2389/Documents/ResearchS25/HypotheSAEs/hypothesaes/lib/python3.13/site-packages (from pydantic<3,>=1.9.0->anthropic) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/katelee2389/Documents/ResearchS25/HypotheSAEs/hypothesaes/lib/python3.13/site-packages (from pydantic<3,>=1.9.0->anthropic) (0.4.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install litellm\n",
    "!pip install mistralai\n",
    "!pip install anthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "629f060f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import Client\n",
    "client = Client(api_key=os.environ[\"OPENAI_API_KEY\"])\n",
    "\n",
    "from litellm import completion\n",
    "from mistralai import Mistral\n",
    "import anthropic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0531c8",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "204e2602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../summeval-data\n"
     ]
    }
   ],
   "source": [
    "current_dir = os.getcwd()\n",
    "if current_dir.endswith(\"notebooks\"):\n",
    "    prefix = \"../\"\n",
    "else:\n",
    "    prefix = \"./\"\n",
    "\n",
    "base_dir = os.path.join(prefix, \"summeval-data\")\n",
    "print(base_dir)\n",
    "\n",
    "full_df = pd.read_json(os.path.join(base_dir, \"summeval_processed_full.jsonl\"), lines=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c67d9f1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['summary', 'expert_annotations', 'turker_annotations', 'references',\n",
      "       'model_id', 'raw', 'mistral_relevance', 'mistral_fluency',\n",
      "       'mistral_coherence', 'mistral_consistency', 'all_annotations',\n",
      "       'scores_coherence_expert', 'scores_coherence_turker',\n",
      "       'scores_coherence_all', 'var_coherence_expert', 'var_coherence_turker',\n",
      "       'var_coherence_all', 'mean_coherence_expert', 'mean_coherence_turker',\n",
      "       'mean_coherence_all', 'var_coherence_expert_disc',\n",
      "       'var_coherence_turker_disc', 'var_coherence_all_disc', 'diff_coherence',\n",
      "       'scores_consistency_expert', 'scores_consistency_turker',\n",
      "       'scores_consistency_all', 'var_consistency_expert',\n",
      "       'var_consistency_turker', 'var_consistency_all',\n",
      "       'mean_consistency_expert', 'mean_consistency_turker',\n",
      "       'mean_consistency_all', 'var_consistency_expert_disc',\n",
      "       'var_consistency_turker_disc', 'var_consistency_all_disc',\n",
      "       'diff_consistency', 'scores_fluency_expert', 'scores_fluency_turker',\n",
      "       'scores_fluency_all', 'var_fluency_expert', 'var_fluency_turker',\n",
      "       'var_fluency_all', 'mean_fluency_expert', 'mean_fluency_turker',\n",
      "       'mean_fluency_all', 'var_fluency_expert_disc',\n",
      "       'var_fluency_turker_disc', 'var_fluency_all_disc', 'diff_fluency',\n",
      "       'scores_relevance_expert', 'scores_relevance_turker',\n",
      "       'scores_relevance_all', 'var_relevance_expert', 'var_relevance_turker',\n",
      "       'var_relevance_all', 'mean_relevance_expert', 'mean_relevance_turker',\n",
      "       'mean_relevance_all', 'var_relevance_expert_disc',\n",
      "       'var_relevance_turker_disc', 'var_relevance_all_disc',\n",
      "       'diff_relevance'],\n",
      "      dtype='object')\n",
      "1600\n"
     ]
    }
   ],
   "source": [
    "print(full_df.columns)\n",
    "print(len(full_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bac76570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n",
      "Index([ 526,  354,  168,  135,  937, 1544, 1253,  237,  478,  650,\n",
      "       ...\n",
      "        163, 1296,  266, 1005,  873,  692, 1450, 1263,  192,  548],\n",
      "      dtype='int64', length=300)\n"
     ]
    }
   ],
   "source": [
    "N_SUBSET = 300\n",
    "\n",
    "selected_df = full_df.sample(n=N_SUBSET, random_state=42)\n",
    "print(len(selected_df))\n",
    "\n",
    "selected_indices = selected_df.index\n",
    "print(selected_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1fc466c",
   "metadata": {},
   "source": [
    "# Build Scoring Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "db6be564",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoring_prompt_with_explanation(article, summary, assertion_text):\n",
    "    prompt = f\"\"\"You will be given one summary written for a news article. \n",
    "Your task is to evaluate the summary on a specific criterion.\n",
    "Please read and understand these instructions carefully.\n",
    "\n",
    "Evaluation Criterion:\n",
    "{assertion_text}\n",
    "\n",
    "Evaluation Steps:\n",
    "1. Read the article and summary carefully.\n",
    "2. Determine whether the summary meets the specified criterion.\n",
    "3. Provide:\n",
    "    - A score of 1 if the criterion is met, or 0 if it is not.\n",
    "    - A brief explanation justifying your score.\n",
    "\n",
    "RESPONSE FORMAT:\n",
    "Score: [0 or 1]\n",
    "Explanation: [one-sentence explanation]\n",
    "\n",
    "Begin below:\n",
    "\n",
    "Article: {article}\n",
    "Summary: {summary}\"\"\"\n",
    "\n",
    "    return prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "61f621ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "assertion_dictionary_og = {\n",
    "    'fluency': {\n",
    "        'C1-A1': 'Fluency measures the quality of individual sentences, are they well-written and grammatically correct. Consider the quality of individual sentences.',\n",
    "        'C1-A2': 'Each sentence is free from grammatical errors and awkward phrasing.',\n",
    "        'C1-A3': 'Contains sentences that are incomplete or lack a clear subject-verb-object structure',\n",
    "        # 'C1-A3': 'Sentences contains grammatical errors and awkward phrasing.', ### negation example\n",
    "    },\n",
    "    'relevance': {\n",
    "        'C2-A1': 'Relevance measures how well the summary captrues the key points of the article. Consider whether all and only the important aspects are contained in the summary.',\n",
    "        'C2-A2': 'Contains no irrelevant or extraneous information unrelated to the article\\'s main points',\n",
    "        'C2-A3': 'Includes all context necessary for understanding key events or claims',\n",
    "        'C2-A4': 'Includes absolutely all information that could reasonably be necessary to evaluate events or claims, even if not central to the article’s key points.',\n",
    "        'C2-A5': 'Includes at least some information needed to understand key events or claims.',\n",
    "    },\n",
    "    'coherence': {\n",
    "        'C3-A1': 'Coherence measures the quality of all sentences collectively, to the fit togheter and soound naturally. Consider the quality of the summary as a whole.',\n",
    "        'C3-A2': 'Sentences in the summary logically progress from one to another without introducing conflicting or unrelated information.',\n",
    "        'C3-A3': 'Maintains logical progression without conflicting or contradictory information',\n",
    "    },\n",
    "    'consistency': {\n",
    "        'C4-A1': \"Consistency measures whether the facts in the summary are consistent with the facts in the original article. COnsider whether the summary does reproduce all facts accurately and does not make up untrue information.\",\n",
    "        'C4-A2': 'The summary includes no fabricated details or misrepresented facts compared to the original article.',\n",
    "        'C4-A3': 'Summary contains only verifiable facts directly present in the original article.',\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aa2509a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "assertion_dictionary_advanced = {\n",
    "    'ambiguity': {\n",
    "        'C1-A1': 'The summary demonstrates appropriate level of detail for the intended reader.',\n",
    "        'C1-A2': 'The summary includes the main claim and supporting evidence from each paragraph of the source article.',\n",
    "    },\n",
    "    'complexity': {\n",
    "        'C2-A1': 'The summary accurately captures the article\\'s key points, maintains neutral tone throughout, demonstrates coherent organization between sentences, and avoids both redundancy and important omissions while preserving the original meaning.',\n",
    "        'C2-A2': 'The summary accurately captures the article\\'s key points.',\n",
    "        'C2-A3': 'The summary maintains neutral tone throughout.',  \n",
    "    },\n",
    "    'language': {\n",
    "        'C3-A1': 'The summary demonstrates high extractive fidelity while maintaining abstractive coherence across semantic boundaries.',\n",
    "        'C3-A2': 'The summary uses words from the original article while connecting ideas in a logical way.',\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1ea646",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Change as needed\n",
    "\n",
    "assertion_dictionary = assertion_dictionary_og"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15aceeb3",
   "metadata": {},
   "source": [
    "# Run Scoring Code\n",
    "\n",
    "Models Used:\n",
    "* {'provider': 'openai', 'model': 'gpt-4o-mini-2024-07-18'} - Recommended # threads: 10\n",
    "* {'provider': 'openai', 'model': 'gpt-3.5-turbo'} - Recommended # threads: 10\n",
    "* {'provider': 'mistral', 'model': 'mistral-small-latest'} - Recommended # threads: 5\n",
    "* {'provider': 'mistral', 'model': 'mistral-medium-latest'} - Recommended # threads: 4\n",
    "* {'provider': 'anthropic', 'model': 'claude-3-5-haiku-20241022'} - Recommended # threads: 7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "895fffa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 14, 1)\n"
     ]
    }
   ],
   "source": [
    "N_SAMPLES = 1 ### number of trials for each data point/ assertion\n",
    "\n",
    "n_assertions = sum(len(assertions) for assertions in assertion_dictionary.values())\n",
    "\n",
    "score_table   = np.full((N_SUBSET, n_assertions, N_SAMPLES), -1, dtype=int)\n",
    "explain_table = np.full((N_SUBSET, n_assertions, N_SAMPLES), \"\", dtype=object)\n",
    "\n",
    "print(score_table.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a59e3007",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS = {\n",
    "    \"gpt-4o-mini\": {\"provider\": \"openai\", \"model\": \"gpt-4o-mini-2024-07-18\", \"threads\": 10},\n",
    "    \"gpt-3.5\": {\"provider\": \"openai\", \"model\": \"gpt-3.5-turbo\", \"threads\": 10},\n",
    "    \"mistral-small\": {\"provider\": \"mistral\", \"model\": \"mistral-small-latest\", \"threads\": 5},\n",
    "    \"mistral-medium\": {\"provider\": \"mistral\", \"model\": \"mistral-medium-latest\", \"threads\": 4},\n",
    "    \"claude-haiku\": {\"provider\": \"anthropic\", \"model\": \"claude-3-5-haiku-20241022\", \"threads\": 7}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bcd568a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_KEY = \"gpt-4o-mini\" ### Change as needed\n",
    "\n",
    "PROVIDER = MODELS[MODEL_KEY][\"provider\"]\n",
    "MODEL = MODELS[MODEL_KEY][\"model\"]\n",
    "RECOMMENDED_THREADS = MODELS[MODEL_KEY][\"threads\"]\n",
    "\n",
    "MAX_TOKENS = 1000\n",
    "MOCK = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb92902",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Default max_retries 3 + exponential delay as more rate limit errors\n",
    "\n",
    "def score_from_prompt(prompt, max_retries=3, initial_delay=4):\n",
    "    retries = 0\n",
    "    delay = initial_delay\n",
    "    \n",
    "    while retries < max_retries:\n",
    "        try:\n",
    "            if retries > 0:\n",
    "                print(\"Attempting Retry #\", retries+1)\n",
    "            time.sleep(2)\n",
    "\n",
    "            content = ModelAPIClient.call_api(\n",
    "                prompt, provider=PROVIDER, model=MODEL, max_tokens=MAX_TOKENS, mock=MOCK\n",
    "            )\n",
    "\n",
    "            if not content:\n",
    "                raise ValueError(\"Empty response\")\n",
    "\n",
    "            content = content.strip()\n",
    "\n",
    "            score_match = re.search(r'Score:\\s*(\\d)', content)\n",
    "            explanation_match = re.search(r'Explanation:\\s*(.+)', content, re.DOTALL)\n",
    "\n",
    "            score = int(score_match.group(1)) if score_match else -1\n",
    "            explanation = explanation_match.group(1).strip() if explanation_match else \"No explanation found\"\n",
    "\n",
    "            if score == -1:\n",
    "                print(\"-1 DETECTED\")\n",
    "            return score, explanation\n",
    "\n",
    "        except Exception as e:\n",
    "            err_str = str(e)\n",
    "            print(f\"[Retry {retries+1}] Error: {err_str}\")\n",
    "            \n",
    "            # Retry if it's a 429 or other rate limit type error\n",
    "            if \"429\" in err_str or \"Rate limit\" in err_str or \"Too Many Requests\" in err_str or \"Empty response\" in err_str:\n",
    "                retries += 1\n",
    "                time.sleep(delay)\n",
    "                delay *= 2  # Exponential backoff\n",
    "            else:\n",
    "                return -1, f\"Error: {err_str}\"\n",
    "\n",
    "    return -1, \"Error: Max retries exceeded\"\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd674ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "START, END = 0, N_SUBSET ### Change the range as needed to run portions of dataset\n",
    "tasks = []\n",
    "\n",
    "for i, row in enumerate(selected_df.iloc[START:END].itertuples(index=False), start=START):\n",
    "    summary = row.summary\n",
    "    raw = row.raw\n",
    "    a_idx = 0\n",
    "    for j, (category, assertions) in enumerate(assertion_dictionary.items()):\n",
    "        for a_id, assertion in assertions.items():\n",
    "            for s in range(N_SAMPLES):\n",
    "                tasks.append((i, a_idx, s, raw, summary, assertion))\n",
    "            a_idx += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaac5c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring: 100%|██████████| 140/140 [01:19<00:00,  1.77it/s]\n"
     ]
    }
   ],
   "source": [
    "max_threads = RECOMMENDED_THREADS ### Change as needed, refer to recommended value above\n",
    "\n",
    "def scoring_task(i, a_idx, s, raw, summary, assertion):\n",
    "    prompt = scoring_prompt_with_explanation(raw, summary, assertion)\n",
    "    score, explanation = score_from_prompt(prompt) ### max_retries= 0, initial_delay=0\n",
    "    return (i, a_idx, s, score, explanation)\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=max_threads) as executor:\n",
    "    future_to_task = {\n",
    "        executor.submit(scoring_task, *task): task for task in tasks\n",
    "    }\n",
    "\n",
    "    for future in tqdm(as_completed(future_to_task), total=len(future_to_task), desc=\"Scoring\"):\n",
    "        i, a_idx, s, score, explanation = future.result()\n",
    "        score_table[i, a_idx, s] = int(score)\n",
    "        explain_table[i, a_idx, s] = explanation or \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4c5ddc5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores up until END are filled appropriately: True\n",
      "All scores are filled appropriately: False\n",
      "Indices with errors: [[ 10   0   0]\n",
      " [ 10   1   0]\n",
      " [ 10   2   0]\n",
      " ...\n",
      " [299  11   0]\n",
      " [299  12   0]\n",
      " [299  13   0]]\n"
     ]
    }
   ],
   "source": [
    "### Sanity check code, especially if experimenting with max_threads\n",
    "\n",
    "no_errors = ~((score_table[:END,:,:] == -1).any())\n",
    "print(\"Scores up until END are filled appropriately:\", no_errors)\n",
    "\n",
    "if not no_errors:\n",
    "    indices = np.argwhere(score_table[:END,:,:] == -1)\n",
    "    print(\"Indices with errors:\", indices)\n",
    "\n",
    "no_errors_all = ~((score_table[:,:,:] == -1).any())\n",
    "print(\"All scores are filled appropriately:\", no_errors_all)\n",
    "\n",
    "if not no_errors_all:\n",
    "    indices = np.argwhere(score_table[:,:,:] == -1)\n",
    "    print(\"Indices with errors:\", indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ce477abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save results\n",
    "\n",
    "output_dir = \"../results/adv\" ### Change to create a new folder as needed\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "np.save(os.path.join(output_dir, f\"score_table_{MODEL}.npy\"), score_table)\n",
    "np.save(os.path.join(output_dir, f\"explain_table_{MODEL}.npy\"), explain_table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hypothesaes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
