{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7e949d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "### MUST SET YOUR OWN OPENAI API KEY HERE\n",
    "os.environ[\"OPENAI_API_KEY\"] = '...'\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import textwrap\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02c79f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import Client\n",
    "client = Client(api_key=os.environ[\"OPENAI_API_KEY\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b2e774",
   "metadata": {},
   "source": [
    "# Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f41fd4d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../summeval-data\n"
     ]
    }
   ],
   "source": [
    "current_dir = os.getcwd()\n",
    "if current_dir.endswith(\"notebooks\"):\n",
    "    prefix = \"../\"\n",
    "else:\n",
    "    prefix = \"./\"\n",
    "\n",
    "base_dir = os.path.join(prefix, \"summeval-data\")\n",
    "print(base_dir)\n",
    "\n",
    "full_df = pd.read_json(os.path.join(base_dir, \"summeval_processed_full.jsonl\"), lines=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6589453c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n",
      "Index([ 526,  354,  168,  135,  937, 1544, 1253,  237,  478,  650,\n",
      "       ...\n",
      "        163, 1296,  266, 1005,  873,  692, 1450, 1263,  192,  548],\n",
      "      dtype='int64', length=300)\n"
     ]
    }
   ],
   "source": [
    "N_SUBSET = 300\n",
    "\n",
    "selected_df = full_df.sample(n=N_SUBSET, random_state=42)\n",
    "print(len(selected_df))\n",
    "\n",
    "selected_indices = selected_df.index\n",
    "print(selected_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a17198d",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    \"gpt-4o-mini-2024-07-18\",\n",
    "    \"gpt-3.5-turbo\",\n",
    "    \"mistral-small-latest\",\n",
    "    \"mistral-medium-latest\",\n",
    "    \"claude-3-5-haiku-20241022\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2824cbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-4o-mini-2024-07-18 → Scores shape: (300, 14, 1), Explains shape: (300, 14, 1)\n",
      "[OK]: Scores & explanations loaded successfully.\n",
      "\n",
      "gpt-3.5-turbo → Scores shape: (300, 14, 1), Explains shape: (300, 14, 1)\n",
      "[OK]: Scores & explanations loaded successfully.\n",
      "\n",
      "mistral-small-latest → Scores shape: (300, 14, 1), Explains shape: (300, 14, 1)\n",
      "[OK]: Scores & explanations loaded successfully.\n",
      "\n",
      "mistral-medium-latest → Scores shape: (300, 14, 1), Explains shape: (300, 14, 1)\n",
      "[OK]: Scores & explanations loaded successfully.\n",
      "\n",
      "claude-3-5-haiku-20241022 → Scores shape: (300, 14, 1), Explains shape: (300, 14, 1)\n",
      "[OK]: Scores & explanations loaded successfully.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output_dir = \"../results/og\"  ### Change as needed\n",
    "score_tables = {}\n",
    "explain_tables = {}\n",
    "\n",
    "for model in models:\n",
    "\n",
    "    score_path = os.path.join(output_dir, f\"score_table_{model}.npy\")\n",
    "    explain_path = os.path.join(output_dir, f\"explain_table_{model}.npy\")\n",
    "\n",
    "    score_tables[model] = np.load(score_path, allow_pickle=True)\n",
    "    explain_tables[model] = np.load(explain_path, allow_pickle=True)\n",
    "\n",
    "    print(f\"{model} → Scores shape: {score_tables[model].shape}, Explains shape: {explain_tables[model].shape}\")\n",
    "    \n",
    "    if np.all(score_tables[model] != -1) and score_tables[model].size > 0 and explain_tables[model].size > 0:\n",
    "        print(f\"[OK]: Scores & explanations loaded successfully.\\n\")\n",
    "    else:\n",
    "        print(f\"[WARN]: Missing or invalid data.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc9659f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "properties_og = [\"fluency\", \"relevance\", \"coherence\", \"consistency\"]\n",
    "\n",
    "assertion_dictionary_og = {\n",
    "    'fluency': {\n",
    "        'C1-A1': 'Fluency measures the quality of individual sentences, are they well-written and grammatically correct. Consider the quality of individual sentences.',\n",
    "        'C1-A2': 'Each sentence is free from grammatical errors and awkward phrasing.',\n",
    "        'C1-A3': 'Contains sentences that are incomplete or lack a clear subject-verb-object structure',\n",
    "        # 'C1-A3': 'Sentences contains grammatical errors and awkward phrasing.', ### negation example\n",
    "    },\n",
    "    'relevance': {\n",
    "        'C2-A1': 'Relevance measures how well the summary captrues the key points of the article. Consider whether all and only the important aspects are contained in the summary.',\n",
    "        'C2-A2': 'Contains no irrelevant or extraneous information unrelated to the article\\'s main points',\n",
    "        'C2-A3': 'Includes all context necessary for understanding key events or claims',\n",
    "        'C2-A4': 'Includes absolutely all information that could reasonably be necessary to evaluate events or claims, even if not central to the article’s key points.',\n",
    "        'C2-A5': 'Includes at least some information needed to understand key events or claims.',\n",
    "    },\n",
    "    'coherence': {\n",
    "        'C3-A1': 'Coherence measures the quality of all sentences collectively, to the fit togheter and soound naturally. Consider the quality of the summary as a whole.',\n",
    "        'C3-A2': 'Sentences in the summary logically progress from one to another without introducing conflicting or unrelated information.',\n",
    "        'C3-A3': 'Maintains logical progression without conflicting or contradictory information',\n",
    "    },\n",
    "    'consistency': {\n",
    "        'C4-A1': \"Consistency measures whether the facts in the summary are consistent with the facts in the original article. COnsider whether the summary does reproduce all facts accurately and does not make up untrue information.\",\n",
    "        'C4-A2': 'The summary includes no fabricated details or misrepresented facts compared to the original article.',\n",
    "        'C4-A3': 'Summary contains only verifiable facts directly present in the original article.',\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619c0feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Change as needed\n",
    "\n",
    "properties = properties_og\n",
    "assertion_dictionary = assertion_dictionary_og"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ee10973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Fluency - C1-A1', 'Fluency - C1-A2', 'Fluency - C1-A3', 'Relevance - C2-A1', 'Relevance - C2-A2', 'Relevance - C2-A3', 'Relevance - C2-A4', 'Relevance - C2-A5', 'Coherence - C3-A1', 'Coherence - C3-A2', 'Coherence - C3-A3', 'Consistency - C4-A1', 'Consistency - C4-A2', 'Consistency - C4-A3']\n",
      "['Fluency - C1-A1\\nFluency measures the quality of individual\\nsentences, are they well-written and grammatically\\ncorrect. Consider the quality of individual\\nsentences.', 'Fluency - C1-A2\\nEach sentence is free from grammatical errors and\\nawkward phrasing.', 'Fluency - C1-A3\\nContains sentences that are incomplete or lack a\\nclear subject-verb-object structure', 'Relevance - C2-A1\\nRelevance measures how well the summary captrues\\nthe key points of the article. Consider whether\\nall and only the important aspects are contained\\nin the summary.', \"Relevance - C2-A2\\nContains no irrelevant or extraneous information\\nunrelated to the article's main points\", 'Relevance - C2-A3\\nIncludes all context necessary for understanding\\nkey events or claims', 'Relevance - C2-A4\\nIncludes absolutely all information that could\\nreasonably be necessary to evaluate events or\\nclaims, even if not central to the article’s key\\npoints.', 'Relevance - C2-A5\\nIncludes at least some information needed to\\nunderstand key events or claims.', 'Coherence - C3-A1\\nCoherence measures the quality of all sentences\\ncollectively, to the fit togheter and soound\\nnaturally. Consider the quality of the summary as\\na whole.', 'Coherence - C3-A2\\nSentences in the summary logically progress from\\none to another without introducing conflicting or\\nunrelated information.', 'Coherence - C3-A3\\nMaintains logical progression without conflicting\\nor contradictory information', 'Consistency - C4-A1\\nConsistency measures whether the facts in the\\nsummary are consistent with the facts in the\\noriginal article. COnsider whether the summary\\ndoes reproduce all facts accurately and does not\\nmake up untrue information.', 'Consistency - C4-A2\\nThe summary includes no fabricated details or\\nmisrepresented facts compared to the original\\narticle.', 'Consistency - C4-A3\\nSummary contains only verifiable facts directly\\npresent in the original article.']\n"
     ]
    }
   ],
   "source": [
    "def _build_assertion_labels(assertion_dictionary):\n",
    "    assertion_labels = []\n",
    "    wrapped_labels = []\n",
    "    for prop, assertions in assertion_dictionary.items():\n",
    "        for a_id, assertion_text in assertions.items():\n",
    "            label = f\"{prop.capitalize()} - {a_id}\"\n",
    "            wrapped = textwrap.fill(assertion_text, width=50)\n",
    "            full_label = f\"{label}\\n{wrapped}\"\n",
    "            assertion_labels.append(label)\n",
    "            wrapped_labels.append(full_label)\n",
    "    return assertion_labels, wrapped_labels\n",
    "\n",
    "assertion_labels, wrapped_labels = _build_assertion_labels(assertion_dictionary)\n",
    "print(assertion_labels)\n",
    "print(wrapped_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d39ced30",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_cases = [\"strong\", \"weak\", \"inverse\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ca4a7a",
   "metadata": {},
   "source": [
    "# 1: Assertion Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b170a2f",
   "metadata": {},
   "source": [
    "### Strong Correlation\n",
    "\n",
    "C4-A1, C4-A2: score 0.93\n",
    "\n",
    "### Weak Correlation\n",
    "\n",
    "C2-A2, C2-A3: score 0.76\n",
    "\n",
    "### Inverse Correlation\n",
    "\n",
    "C1-A2, C1-A3: score -0.57"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9648ea8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_values = {\n",
    "    \"strong\": 0.93,\n",
    "    \"weak\": 0.76,\n",
    "    \"inverse\": -0.57\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0a0135",
   "metadata": {},
   "source": [
    "# 2: Sorted Case View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d0c67cc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'strong': (11, 12), 'weak': (4, 5), 'inverse': (1, 2)}\n"
     ]
    }
   ],
   "source": [
    "assertion_pair_indices = {\n",
    "    \"strong\": (\n",
    "        assertion_labels.index(\"Consistency - C4-A1\"),\n",
    "        assertion_labels.index(\"Consistency - C4-A2\")\n",
    "    ),\n",
    "    \"weak\": (\n",
    "        assertion_labels.index(\"Relevance - C2-A2\"),\n",
    "        assertion_labels.index(\"Relevance - C2-A3\")\n",
    "    ),\n",
    "    \"inverse\": (\n",
    "        assertion_labels.index(\"Fluency - C1-A2\"),\n",
    "        assertion_labels.index(\"Fluency - C1-A3\")\n",
    "    )\n",
    "}\n",
    "\n",
    "print(assertion_pair_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7aaa8f45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 14)\n"
     ]
    }
   ],
   "source": [
    "avg_scores_across_models = np.mean(np.stack([score_table_model for score_table_model in score_tables.values()]), axis=0)  # shape: (300, 12)\n",
    "avg_scores_across_models = avg_scores_across_models.squeeze()\n",
    "print(avg_scores_across_models.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "52d88445",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_strong_items(scores, a_idx1, a_idx2, sample_n=5):\n",
    "    cond = (scores[:, a_idx1] == scores[:, a_idx2])\n",
    "    full_indices = np.where(cond)[0]\n",
    "\n",
    "    if len(full_indices) >= sample_n:\n",
    "        sampled_indices = np.random.choice(full_indices, size=sample_n, replace=False)\n",
    "    else:\n",
    "        sampled_indices = full_indices  \n",
    "\n",
    "    return full_indices, sampled_indices\n",
    "\n",
    "INV_THRESHOLD_LOW = 0.2\n",
    "INV_THRESHOLD_HIGH = 0.8\n",
    "\n",
    "def get_inverse_items(scores, a_idx1, a_idx2, sample_n=5):\n",
    "    cond = ((scores[:, a_idx1] >= INV_THRESHOLD_HIGH) & (scores[:, a_idx2] <= INV_THRESHOLD_LOW)) | \\\n",
    "           ((scores[:, a_idx1] <= INV_THRESHOLD_LOW) & (scores[:, a_idx2] >= INV_THRESHOLD_HIGH))\n",
    "    full_indices = np.where(cond)[0]\n",
    "\n",
    "    if len(full_indices) >= sample_n:\n",
    "        sampled_indices = np.random.choice(full_indices, size=sample_n, replace=False)\n",
    "    else:\n",
    "        sampled_indices = full_indices\n",
    "\n",
    "    return full_indices, sampled_indices\n",
    "\n",
    "def get_weak_items(scores, a_idx1, a_idx2, sample_n=5):\n",
    "    total = scores.shape[0]\n",
    "    return np.random.choice(total, size=sample_n, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "48ac1b84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strong (11, 12): [191 240 134 279 264] (Sampled) (Total: 220)\n",
      "Inverse (1, 2): [201  16  13 123  96] (Sampled) (Total: 127)\n",
      "Weak (4, 5): [ 30  10 215  13 241] (Sampled) (Total: 5)\n"
     ]
    }
   ],
   "source": [
    "a_idx_strong = assertion_pair_indices[\"strong\"]\n",
    "a_idx_weak = assertion_pair_indices[\"weak\"]\n",
    "a_idx_inverse = assertion_pair_indices[\"inverse\"]\n",
    "\n",
    "# Run and display results\n",
    "strong_all, strong_sample = get_strong_items(avg_scores_across_models, *a_idx_strong)\n",
    "print(f\"Strong {a_idx_strong}: {strong_sample} (Sampled) (Total: {len(strong_all)})\")\n",
    "\n",
    "inverse_all, inverse_sample = get_inverse_items(avg_scores_across_models, *a_idx_inverse)\n",
    "print(f\"Inverse {a_idx_inverse}: {inverse_sample} (Sampled) (Total: {len(inverse_all)})\")\n",
    "\n",
    "weak_sample = get_weak_items(avg_scores_across_models, *a_idx_weak)\n",
    "print(f\"Weak {a_idx_weak}: {weak_sample} (Sampled) (Total: {len(weak_sample)})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a51ecc",
   "metadata": {},
   "source": [
    "# 3: P-value/ Confidence Interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "181670ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Strong Correlation:\n",
      "  Assertions: Consistency - C4-A1 vs. Consistency - C4-A2\n",
      "  Pearson r: 0.932\n",
      "  p-value: 9.92992240443276e-134\n",
      "\n",
      "Weak Correlation:\n",
      "  Assertions: Relevance - C2-A2 vs. Relevance - C2-A3\n",
      "  Pearson r: 0.765\n",
      "  p-value: 7.98319050865786e-59\n",
      "\n",
      "Inverse Correlation:\n",
      "  Assertions: Fluency - C1-A2 vs. Fluency - C1-A3\n",
      "  Pearson r: -0.567\n",
      "  p-value: 6.71202857035294e-27\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "for label, (a_idx1, a_idx2) in assertion_pair_indices.items():\n",
    "    a1_scores = avg_scores_across_models[:, a_idx1]\n",
    "    a2_scores = avg_scores_across_models[:, a_idx2]\n",
    "    \n",
    "    corr, p_value = pearsonr(a1_scores, a2_scores)\n",
    "    print(f\"\\n{label.capitalize()} Correlation:\")\n",
    "    print(f\"  Assertions: {assertion_labels[a_idx1]} vs. {assertion_labels[a_idx2]}\")\n",
    "    print(f\"  Pearson r: {corr:.3f}\")\n",
    "    print(f\"  p-value: {p_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387c77cb",
   "metadata": {},
   "source": [
    "# 4: Diagnostic Prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a2491d",
   "metadata": {},
   "source": [
    "## 4.1: Build Diagnostic Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "95aae261",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_hypothesis_prompt_iter2(df, input_col, output_col, \n",
    "                             assertion_text_1, assertion_text_2,\n",
    "                             assertion_type_1, assertion_type_2,\n",
    "                             correlation_strength, correlation_value, p_value,\n",
    "                             assertion_scores, item_indices, *,\n",
    "                             include_categories=True):\n",
    "    \n",
    "    prompt = f\"\"\"Your job is to help understand statistical relationships between two binary assertions used to evaluate AI system behavior.\n",
    "\n",
    "Assertion Details:\n",
    "* A1: {assertion_text_1}\n",
    "* A2: {assertion_text_2}\n",
    "* Assertion types: {assertion_type_1} and {assertion_type_2}\n",
    "\n",
    "Correlation Analysis:\n",
    "* Correlation coefficient: {correlation_value:.3f}\n",
    "* Correlation strength: {correlation_strength}\n",
    "* Statistical significance: p = {p_value:.4g}\n",
    "\n",
    "Based on the following list of Generative AI system inputs and outputs and corresponding assertion values, generate hypotheses for why the assertions exhibit this correlation pattern. \n",
    "Hypotheses should describe very specific logical or semantic relationships between assertions that describe correlation patterns. \n",
    "\n",
    "For example, hypotheses might identify patterns such as: \n",
    "- The two assertions capture fundamentally different concepts\n",
    "- One assertion is a logical negation, subset, or superset of another\n",
    "- The assertions capture similar or redundant information about system behavior\n",
    "- The assertions tend to fail together or in opposing patterns under certain conditions\n",
    "\n",
    "Hypotheses should not state vague or general observations, such as the assertions are related to one another. They should be much more specific. \n",
    "\n",
    "Example hypotheses:\n",
    "* \"The two assertions capture different concepts with minimal overlap\"\n",
    "* \"One assertion is a logical negation of another, creating inverse correlation\"\n",
    "* \"Assertion 1 is more sensitive to edge cases than Assertion 2\"\n",
    "* \"The assertions have different thresholds, with A1 being more restrictive than A2\"\n",
    "\"\"\"\n",
    "\n",
    "    # Add the 5 data items\n",
    "    for idx, row_idx in enumerate(item_indices, 1):\n",
    "        row = df.iloc[row_idx]\n",
    "        a1_score, a2_score = assertion_scores[row_idx]\n",
    "        prompt += f\"\"\"\n",
    "Item {idx}: \n",
    "Input: {getattr(row, input_col)}\n",
    "Output: {getattr(row, output_col)}\n",
    "Assertion 1: {a1_score:.1f}\n",
    "Assertion 2: {a2_score:.1f}\n",
    "\"\"\"\n",
    "    prompt += \"\"\"\n",
    "Instructions: Return 5 hypotheses for the observed correlation pattern, formatted as \"Hypothesis {#}: {hypothesis statement}\".\n",
    "\"\"\"\n",
    "\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e68bc9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "assertion_types = {\n",
    "    \"strong\": (\"performance-related\", \"performance-related\"),\n",
    "    \"weak\": (\"performance-related\", \"performance-related\"),\n",
    "    \"inverse\": (\"performance-related\", \"performance-related\"),\n",
    "}\n",
    "\n",
    "def get_assertion_text(label):\n",
    "    concept, a_id = label.split(\" - \")\n",
    "    return assertion_dictionary[concept.lower()][a_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "822d24ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your job is to help understand statistical relationships between two binary assertions used to evaluate AI system behavior.\n",
      "\n",
      "Assertion Details:\n",
      "* A1: Each sentence is free from grammatical errors and awkward phrasing.\n",
      "* A2: Contains sentences that are incomplete or lack a clear subject-verb-object structure\n",
      "* Assertion types: performance-related and performance-related\n",
      "\n",
      "Correlation Analysis:\n",
      "* Correlation coefficient: -0.570\n",
      "* Correlation strength: inverse\n",
      "* Statistical significance: p = 6.712e-27\n",
      "\n",
      "Based on the following list of Generative AI system inputs and outputs and corresponding assertion values, generate hypotheses for why the assertions exhibit this correlation pattern. \n",
      "Hypotheses should describe very specific logical or semantic relationships between assertions that describe correlation patterns. \n",
      "\n",
      "For example, hypotheses might identify patterns such as: \n",
      "- The two assertions capture fundamentally different concepts\n",
      "- One assertion is a logical negation, subset, or superset of another\n",
      "- The assertions capture similar or redundant information about system behavior\n",
      "- The assertions tend to fail together or in opposing patterns under certain conditions\n",
      "\n",
      "Hypotheses should not state vague or general observations, such as the assertions are related to one another. They should be much more specific. \n",
      "\n",
      "Example hypotheses:\n",
      "* \"The two assertions capture different concepts with minimal overlap\"\n",
      "* \"One assertion is a logical negation of another, creating inverse correlation\"\n",
      "* \"Assertion 1 is more sensitive to edge cases than Assertion 2\"\n",
      "* \"The assertions have different thresholds, with A1 being more restrictive than A2\"\n",
      "\n",
      "Item 1: \n",
      "Input: There would have been no mercy in the dressing room. Nothing is sacred in the team. When Ben Stokes first turned up at the Kensington Oval this week someone would have said: ‘Mind that locker, Stokesey.’ It was here, of course, that Stokes broke his wrist punching a locker after being dismissed last year and that will be a reminder to him of the need to channel his aggression in the right way now he is back in the England team. Ben Stokes has forged a reputation as a fiery character in the England cricket team Stokes (left) clashed with Marlon Samuels during the second Test between West Indies and England But Stokes (right) responded positively to the row after talking to England coach Peter Moores Only a slight niggle in his back might stop Stokes playing here in Barbados and I am glad he has fought his way back after what has been a year of ups and downs. I like Stokes and I like his character at a time when the game can be perceived as producing robots and players who cannot capture the imagination. He has something about him, as he showed when he was in Mitchell Johnson’s face during the Ashes series. He was not worried about the bombardment he would get in return. But I do believe he will need careful man-managing. Peter Moores, England’s coach, dragged him to one side after his clash with Marlon Samuels in the second Test and had a long chat with him and if it was to talk about how he should respond then the advice he gave was clearly right. The way he approached the Jamaican after that third-day salute was spot on. England must make sure they do not quash that natural exuberance and desire to take someone on. It will not always come off but we have to accept that there will be lows as well as highs with this lad. What Stokes must not do is try to live up to his reputation and become pigeon-holed. He can be feisty and fiery as long as it’s natural but his aggression has to be controlled. You want the character as long as the end product is runs and wickets. Stokes (second left) can use his aggression to bring runs and wickets to the England team Stokes (left) congratulates England captain Alastair Cook after the side won the second Test England want to have Stokes in the team as much as possible to help him hit his full potential Let him go a bit but rein him in occasionally. There is an argument here to play the second spinner in Adil Rashid and if England went down that route in Bridgetown the place of Stokes or Chris Jordan would come into question but they clearly want both to play as much as possible. This summer there will rarely be the need for two spinners so England want these two exciting cricketers to grow into the international game. They can only get better and that’s an exciting prospect.\n",
      "Output: ben stokes has forged a reputation as a fiery character in the england cricket team . stokes broke his wrist punching a locker after being dismissed last year . he was not worried about the bombardment he would get in return .\n",
      "Assertion 1: 0.2\n",
      "Assertion 2: 0.8\n",
      "\n",
      "Item 2: \n",
      "Input: Chelsea have made an offer for FC Tokyo's 22-year-old forward Yoshinori Muto, according to club president Naoki Ogane. The Japan international, who has played for the J-League side since 2013, will join Chelsea's Dutch partner club Vitesse Arnhem on loan next season if he completes a move to Stamford Bridge this summer. Ogane claims that Chelsea's interest in Muto is not connected to the £200million sponsorship deal they signed with Japanese company Yokohama Rubber in February. FC Tokyo forward Yoshinori Muto (centre) brings the ball forward against Albirex Niigata in March FC Tokyo president Naoki Ogane claims that Chelsea have made a bid for Japan international Muto Muto tussles with Yuji Nakazawa of Yokohama F.Marinos during a J-League clash last month Age: 22 Club: FC Tokyo Appearances: 37 Goals: 16 International caps (Japan): 11 International goals: 1 Did you know? Muto graduated from Keio University in Tokyo with an economics degree two weeks ago Speaking to Sports Nippon, Ogane said: 'It is true that Chelsea sent us an offer for Muto. 'It is a formal offer with conditions. They want to acquire him in the summer.' Muto, who only graduated from Keio University a fortnight ago after completing an economics degree, would be the first Japanese player to represent Chelsea if he moves to west London. He has earned 11 caps for his country after signing his first professional contract in 2014, scoring once for the Samurai Blue. A £4million deal for the youngster has been mooted, but Muto admits that he isn't sure if he will join the Premier League title chasers despite being pleased with their bid. He said: 'I have not decided yet at all. It is an honour for me to receive this offer from a great club.' Muto scored 13 times in his debut season with FC Tokyo and was named in the J-League's best XI. Muto admits it is an 'honour' to receive an offer from Chelsea although he has not yet decided to join the club Muto, pictured in action against Ventforet Kofu has scored three goals in four games so far this season The 22-year-old has a shot at goal during Japan's Asian Cup match against Palestine in January this year He has continued his fine form during the current campaign, helping his club to third place in the division with three goals in four games. Yokohama Rubber - one of the world's largest tyre manufacturers - will become Chelsea's official shirt sponsors from the start of the 2015-16 season. The initial five-year deal is the biggest in the club's history, with the Blues now considering a two-week pre-season tour of Japan this summer.\n",
      "Output: chelsea have made an offer for fc tokyo 's yoshinori muto . japan international will join chelsea 's vitesse arnhem on loan next season . muto claims chelsea 's interest in muto is not connected to the # 200million deal they signed with yokohama rubber in february .\n",
      "Assertion 1: 0.2\n",
      "Assertion 2: 0.8\n",
      "\n",
      "Item 3: \n",
      "Input: Thousands of holidaymakers caught up in last summer’s passport delay fiasco have not received any compensation. At the same time, managers at the passport agency, which made a £42 million profit during the chaos, received up to £3,500 in bonuses. Ministers refused to give a blanket refund to the desperate families who had to pay extra to get their travel documents rushed through, and even to some who missed out on trips. Scroll down for video The boxes of passport applications piled up at in office in Liverpool at the peak of the backlog last summer Keith Vaz, who as chairman of the Home Affairs Committee led the calls for compensation, said last night: ‘I am astonished so few people have been given compensation for what was a fiasco presided over by the management of the passport office, especially as they made a profit last year that ran into millions of pounds.’ The problems began a year ago as HM Passport Office struggled to cope with 3.6 million Britons applying for documents. By mid-June there were more than half a million passports stuck in the system. Ministers agreed to give urgent cases a free upgrade to the fast-track service, but thousands had already paid the extra £30 per passport for this. Many still missed trips because their passports did not arrive in time. Details obtained by The Mail on Sunday show scarcely any of the thousands of holidaymakers caught up in the chaos ever got anything back from the Passport Office. In total just 2,191 compensation applications were approved between April last year and January this year, scarcely changed from 2,077 for the previous year. The total paid out was £203,066, giving an average sum of £92.68. The biggest single payout was £5,463; the lowest £1. The Passport Office said it could not say how many claims were rejected, partly because of ‘the system failure of our customer complaint database’. It can be revealed however that Ministers rejected a demand by the Home Affairs Select Committee for all those left out of pocket to be compensated, saying: ‘It would create a precedent.’ Home Affairs Committee chairman Keith Vaz led the calls for compensation and was 'astonished' to learn just 2,191 compensation applications were approved This newspaper contacted more than a dozen holidaymakers who had either missed trips or had to pay extra to get passports in time. Only one had got money back. Among those refused were Mathew Bean and Hayley Kirkham. They lost close to £1,500 on a trip to Morocco, where he had planned to propose, because their passports did not arrive in time – even though they had applied ten weeks before they were due to travel and paid for upgrades. HM Passport Office made a surplus of £42.3 million between April and October last year. In 2013-14, the most recent figures available, managers were handed a total of £1.8 million in bonuses, with the average reward £499 and the highest £3,500.\n",
      "Output: thousands of holidaymakers caught up in last summer 's passport delay fiasco have not received any compensation . at the same time , managers at the passport agency , which made a # 42 million profit during the chaos , received up to # 3,500 in bonuses . ministers refused to give a blanket refund to the desperate families who had to pay extra to get their travel documents rushed through .\n",
      "Assertion 1: 0.2\n",
      "Assertion 2: 0.8\n",
      "\n",
      "Item 4: \n",
      "Input: Kaitlyn Granado, 24, was arrested on Monday amid claims she had sex with pupil, 15, in her car on consecutive nights in January A Texas math teacher has been accused of having sex with an underage pupil from a Texas high school a month after she was arrested for letting another teenage touch her breasts. Kaitlyn Granado, 24, a teacher at MacArthur High School in Irving, was first arrested on March 19 for having an inappropriate relationship with a 15-year-old student, and was released on bail. Now she has been arrested again after another pupil, also aged 15, also accused Granado of having sex with him on two consecutive nights in January this year. According to the affidavit, seen by the Star-Telegram, the teen claims the sexual relationship took place in her car late at night on January 18 and 19 across the road from another school in Dallas. The abuse came to light after a school police officer learned of a possible relationship between Granado and one of the boys last month. She was arrested on March 19, and in a police interview she admitted kissing the pupil and allowing him to touch her breasts in April the previous year, according to the Dallas Morning News. She was subsequently suspended from teaching and put on administrative leave by school officials. At the time, detectives said they didn't think she had been in a relationship with any other pupils, but just days later, on March 24, officers quizzed a second boy about a possible relationship with her. A spokesman for the police department said: 'There was some discussion, some rumoring, there may have been a second person involved. 'That information came from within the school, and it turned out to be true.' Granado, who is a maths teacher at MacArthur High School in Irving, Texas (pictured), was also arrested last month when she admitted kissing another boy, also 15, and lettin him touch her breasts Granado was booked into Irving County Jail for the second time on Monday, and released after posting a $50,000 bail. It is not known how Granado intends to plead to the second set of charges against her. A spokesman for Irving school district said: 'While privacy laws prevent us from sharing specific details, we can reassure our families that we took immediate and appropriate action. 'Being on administrative leave prevents her from working with students and being present on any Irving ISD property.'\n",
      "Output: kaitlyn granado , 24 , a teacher at macarthur high school in irving , texas , was first arrested on march 19 for having an inappropriate relationship with a 15-year-old student , and was released on bail . now she has been arrested again after another pupil , also accused granado of having sex with him on two consecutive nights in january this year . the teen claims the sexual relationship took place in her car late at night on january 18 and 19 .\n",
      "Assertion 1: 0.2\n",
      "Assertion 2: 0.8\n",
      "\n",
      "Item 5: \n",
      "Input: England ace Joe Hart labelled fellow goalkeeper Gianluigi Buffon a 'legend of the game' after seeing the Italian veteran claim his 147th cap. Hart, who passed an impressive milestone of his own by representing his country for the 50th time on Tuesday night, said after the 1-1 draw with Italy that Buffon was an inspiration. Speaking to FA TV, Hart said: 'I’m still learning my game and I’m still watching the likes of Buffon and the way he goes about his business at 37 years old. England and Manchester City goalkeeper Joe Hart has lavished praise on fellow goalkeeper Gianluigi Buffon Hart has labelled Buffon, who won his 147th cap against England on Tuesday night, a 'legend of the game' 'I’ve got a lot more learning to do and I want to do it in this team. '[Buffon’s caps total] is a long way off, but it’s definitely a night to celebrate a terrific goalkeeper and a legend of the game, someone I personally look up to and it’s inspirational to see.' The Manchester City shot stopper, who is 10 years younger than Buffon, revealed his delight at receiving his 50th cap at the Juventus Stadium. 'I was proud of my first cap, I was proud to represent the Under 21s, and 50 caps at my age is good,' added Hart. 'I want to keep going, that’s not the end for me. I just want to keep going, keep playing well for my club and country and rack them up.' England ace Hart, pictured saving a shot by Citadin Eder, is desperate to add to his 50 international caps\n",
      "Output: joe hart says gianluigi buffon is a ` legend of the game ' after 1-1 draw with italy . the manchester city goalkeeper is desperate to add to his 50 international caps . the manchester city shot stopper , who is 10 years younger than buffon .\n",
      "Assertion 1: 0.0\n",
      "Assertion 2: 1.0\n",
      "\n",
      "Instructions: Return 5 hypotheses for the observed correlation pattern, formatted as \"Hypothesis {#}: {hypothesis statement}\".\n",
      "\n"
     ]
    }
   ],
   "source": [
    "diagnostic_prompts = {}\n",
    "\n",
    "for case in correlation_cases:\n",
    "    idx1, idx2 = assertion_pair_indices[case]\n",
    "    a1_label, a2_label = assertion_labels[idx1], assertion_labels[idx2]\n",
    "    \n",
    "    a1_text = get_assertion_text(a1_label)\n",
    "    a2_text = get_assertion_text(a2_label)\n",
    "\n",
    "    scores = avg_scores_across_models[:, [idx1, idx2]]\n",
    "\n",
    "    if case == \"strong\":\n",
    "        item_indices = strong_sample\n",
    "    elif case == \"weak\":\n",
    "        item_indices = weak_sample\n",
    "    else:\n",
    "        item_indices = inverse_sample\n",
    "\n",
    "    r_val = correlation_values[case]\n",
    "\n",
    "    _, p_val = pearsonr(avg_scores_across_models[:, idx1], avg_scores_across_models[:, idx2])\n",
    "\n",
    "    type1, type2 = assertion_types[case]\n",
    "\n",
    "    prompt = build_hypothesis_prompt_iter2(\n",
    "        df=selected_df,\n",
    "        input_col=\"raw\",\n",
    "        output_col=\"summary\",\n",
    "        assertion_text_1=a1_text,\n",
    "        assertion_text_2=a2_text,\n",
    "        assertion_type_1=type1,\n",
    "        assertion_type_2=type2,\n",
    "        correlation_strength=case,\n",
    "        correlation_value=r_val,\n",
    "        p_value=p_val,\n",
    "        assertion_scores=scores,\n",
    "        item_indices=item_indices,\n",
    "        include_categories=True, ### toggle \n",
    "    )\n",
    "\n",
    "    diagnostic_prompts[case] = prompt\n",
    "\n",
    "print(diagnostic_prompts[\"inverse\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd7d13b",
   "metadata": {},
   "source": [
    "## 4.2: Run Diagnositic Prompt - OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d15603d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def parse_hypotheses_to_list(hypotheses_text):\n",
    "    chunks = re.split(r'\\bHypothesis\\s*\\d+\\s*:\\s*', hypotheses_text)\n",
    "    \n",
    "    parsed = [chunk.strip() for chunk in chunks if chunk.strip()]\n",
    "    \n",
    "    return parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2e046d3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case:  strong\n",
      "Case:  weak\n",
      "Case:  inverse\n",
      "{'strong': ['The two assertions capture similar or redundant information about system behavior, as both focus on the accuracy and truthfulness of the summary in relation to the original article, leading to a high correlation.', 'Assertion 2 is a logical subset of Assertion 1. While Assertion 1 includes both consistency and truthfulness, Assertion 2 specifically highlights the absence of fabricated details, which is inherently a component of overall consistency.', 'The assertions tend to fail together under conditions where the AI system introduces any factual inaccuracies or makes up information, as any fabrication would inherently affect both consistency and the presence of fabricated details.', 'The strong correlation may be due to both assertions operating under similar thresholds, where even minor inconsistencies or fabrications are flagged, resulting in similar assertion values across different inputs.', 'The assertions are semantically aligned such that any failure to reproduce facts accurately in the summary (Assertion 1) will automatically imply the inclusion of fabricated details or misrepresented facts (Assertion 2), leading to strong correlation.'], 'weak': ['The two assertions capture overlapping yet distinct dimensions of relevance and comprehensiveness, where A1 focuses on excluding extraneous details and A2 emphasizes the inclusion of crucial context, leading to a strong positive correlation when both are satisfied.', 'The correlation between the assertions may arise because failing to include necessary context (A2) often coincides with the presence of irrelevant information (A1), as a lack of focus can result in both omissions and irrelevant additions.', \"Assertion 1 might be assessed more strictly, evaluating any extraneous content as a failure, while Assertion 2 could allow for some missing context as long as the key points remain understandable, explaining why they don't always align perfectly.\", \"The assertions might capture similar information about the AI's ability to produce concise and contextually rich outputs, thus exhibiting positive correlation, but diverge in cases where an output is contextually sufficient without being overly concise.\", 'The correlation pattern suggests that both assertions tend to fail together when the AI system struggles with maintaining focus or relevance, but they might diverge in cases where the system includes all necessary context yet also introduces irrelevant details.'], 'inverse': ['Assertion 1 and Assertion 2 capture different aspects of sentence structure, with Assertion 1 focusing on overall grammatical correctness and fluency, while Assertion 2 specifically targets structural completeness. Therefore, an output can have awkward but complete sentences, leading to an inverse correlation.', 'Assertion 1 is effectively a logical negation of Assertion 2, as sentences that have clear subject-verb-object structures (and are thus complete) are less likely to be riddled with grammatical errors or awkward phrasing, resulting in an inverse correlation.', 'The two assertions have different sensitivity levels, with Assertion 1 being more sensitive to nuanced grammatical issues and awkward phrasing, whereas Assertion 2 is strictly concerned with the presence of a basic sentence structure, leading to the observed inverse correlation.', 'Assertion 1 and Assertion 2 can be seen as capturing overlapping but not identical language quality metrics. Assertion 1 covers a broader range of linguistic errors including awkward phrasing, while Assertion 2 is narrowly focused on sentence completeness, frequently causing them to diverge in evaluation.', 'In many cases, outputs that satisfy Assertion 2 (having complete sentence structures) might still fail Assertion 1 due to non-structural errors like awkward phrasing, creating a situation where fulfilling one assertion can inversely affect the other.']}\n"
     ]
    }
   ],
   "source": [
    "dict_hypotheses = {case: [] for case in correlation_cases}\n",
    "\n",
    "for i, case in enumerate(correlation_cases):\n",
    "    print(\"Case: \", case)\n",
    "    prompt = diagnostic_prompts[case]\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",  \n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are an expert in analyzing evaluation criteria and interpreting statistical correlations in AI behavior assessments.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=0.7,\n",
    "        max_tokens=1000,\n",
    "    )\n",
    "    hypotheses = response.choices[0].message.content.strip()\n",
    "    hypotheses_list = parse_hypotheses_to_list(hypotheses)\n",
    "    dict_hypotheses[case] = hypotheses_list\n",
    "    \n",
    "print(dict_hypotheses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "73768b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== STRONG ===\n",
      "Old Assertion 1 (Consistency - C4-A1):  Consistency measures whether the facts in the summary are consistent with the facts in the original article. COnsider whether the summary does reproduce all facts accurately and does not make up untrue information.\n",
      "Old Assertion 2 (Consistency - C4-A2):  The summary includes no fabricated details or misrepresented facts compared to the original article.\n",
      "\n",
      "Hypothesis 1: The two assertions capture similar or redundant information about system behavior, as both focus on the accuracy and truthfulness of the summary in relation to the original article, leading to a high correlation.\n",
      "Hypothesis 2: Assertion 2 is a logical subset of Assertion 1. While Assertion 1 includes both consistency and truthfulness, Assertion 2 specifically highlights the absence of fabricated details, which is inherently a component of overall consistency.\n",
      "Hypothesis 3: The assertions tend to fail together under conditions where the AI system introduces any factual inaccuracies or makes up information, as any fabrication would inherently affect both consistency and the presence of fabricated details.\n",
      "Hypothesis 4: The strong correlation may be due to both assertions operating under similar thresholds, where even minor inconsistencies or fabrications are flagged, resulting in similar assertion values across different inputs.\n",
      "Hypothesis 5: The assertions are semantically aligned such that any failure to reproduce facts accurately in the summary (Assertion 1) will automatically imply the inclusion of fabricated details or misrepresented facts (Assertion 2), leading to strong correlation.\n",
      "\n",
      "=== WEAK ===\n",
      "Old Assertion 1 (Relevance - C2-A2):  Contains no irrelevant or extraneous information unrelated to the article's main points\n",
      "Old Assertion 2 (Relevance - C2-A3):  Includes all context necessary for understanding key events or claims\n",
      "\n",
      "Hypothesis 1: The two assertions capture overlapping yet distinct dimensions of relevance and comprehensiveness, where A1 focuses on excluding extraneous details and A2 emphasizes the inclusion of crucial context, leading to a strong positive correlation when both are satisfied.\n",
      "Hypothesis 2: The correlation between the assertions may arise because failing to include necessary context (A2) often coincides with the presence of irrelevant information (A1), as a lack of focus can result in both omissions and irrelevant additions.\n",
      "Hypothesis 3: Assertion 1 might be assessed more strictly, evaluating any extraneous content as a failure, while Assertion 2 could allow for some missing context as long as the key points remain understandable, explaining why they don't always align perfectly.\n",
      "Hypothesis 4: The assertions might capture similar information about the AI's ability to produce concise and contextually rich outputs, thus exhibiting positive correlation, but diverge in cases where an output is contextually sufficient without being overly concise.\n",
      "Hypothesis 5: The correlation pattern suggests that both assertions tend to fail together when the AI system struggles with maintaining focus or relevance, but they might diverge in cases where the system includes all necessary context yet also introduces irrelevant details.\n",
      "\n",
      "=== INVERSE ===\n",
      "Old Assertion 1 (Fluency - C1-A2):  Each sentence is free from grammatical errors and awkward phrasing.\n",
      "Old Assertion 2 (Fluency - C1-A3):  Contains sentences that are incomplete or lack a clear subject-verb-object structure\n",
      "\n",
      "Hypothesis 1: Assertion 1 and Assertion 2 capture different aspects of sentence structure, with Assertion 1 focusing on overall grammatical correctness and fluency, while Assertion 2 specifically targets structural completeness. Therefore, an output can have awkward but complete sentences, leading to an inverse correlation.\n",
      "Hypothesis 2: Assertion 1 is effectively a logical negation of Assertion 2, as sentences that have clear subject-verb-object structures (and are thus complete) are less likely to be riddled with grammatical errors or awkward phrasing, resulting in an inverse correlation.\n",
      "Hypothesis 3: The two assertions have different sensitivity levels, with Assertion 1 being more sensitive to nuanced grammatical issues and awkward phrasing, whereas Assertion 2 is strictly concerned with the presence of a basic sentence structure, leading to the observed inverse correlation.\n",
      "Hypothesis 4: Assertion 1 and Assertion 2 can be seen as capturing overlapping but not identical language quality metrics. Assertion 1 covers a broader range of linguistic errors including awkward phrasing, while Assertion 2 is narrowly focused on sentence completeness, frequently causing them to diverge in evaluation.\n",
      "Hypothesis 5: In many cases, outputs that satisfy Assertion 2 (having complete sentence structures) might still fail Assertion 1 due to non-structural errors like awkward phrasing, creating a situation where fulfilling one assertion can inversely affect the other.\n"
     ]
    }
   ],
   "source": [
    "for case in correlation_cases:\n",
    "    idx1, idx2 = assertion_pair_indices[case]\n",
    "    a1_label, a2_label = assertion_labels[idx1], assertion_labels[idx2]\n",
    "\n",
    "    a1_text = get_assertion_text(a1_label)\n",
    "    a2_text = get_assertion_text(a2_label)\n",
    "\n",
    "    hyps = dict_hypotheses.get(case, []) or []\n",
    "\n",
    "    print(f\"\\n=== {case.upper()} ===\")\n",
    "    print(f\"Old Assertion 1 ({a1_label}):  {a1_text}\")\n",
    "    print(f\"Old Assertion 2 ({a2_label}):  {a2_text}\\n\")\n",
    "\n",
    "    for i, h in enumerate(hyps[:5], start=1):\n",
    "        print(f\"Hypothesis {i}: {h}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa57f8d",
   "metadata": {},
   "source": [
    "# 5: Refinement Prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9699a1cf",
   "metadata": {},
   "source": [
    "## 5.1 Build Refinement Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b3ef0ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_combined_assertion_prompt_iter2(assertion_1_text,assertion_2_text,correlation_strength,correlation_value,p_value,diagnosed_issue,specific_hypothesis,example_assertions=None):\n",
    "    prompt = f\"\"\"Your job is to help understand statistical relationships between two binary assertions used to evaluate AI system behavior. Based on a hypothesized relationship between these assertions, your task is to generate new assertions that resolve the identified issues. \n",
    "\n",
    "Assertion Details:\n",
    "A1: {assertion_1_text}\n",
    "A2: {assertion_2_text}\n",
    "\n",
    "Correlation Analysis:\n",
    "Correlation coefficient: {correlation_value:.3f}\n",
    "Correlation strength: {correlation_strength}\n",
    "Statistical significance: p = {p_value:.4g}\n",
    "\n",
    "Diagnosed issue (general): {diagnosed_issue}\n",
    "Specific hypothesis: {specific_hypothesis}\n",
    "\n",
    "Generate five new assertions that combine A1 and A2 while preserving the main evaluation goals. Assertions should be binary statements that can be evaluated for each target system input-output pair.\"\"\"\n",
    "    \n",
    "    if example_assertions:\n",
    "        prompt += \"\\n\\nFor example:\"\n",
    "        for ex in example_assertions:\n",
    "            prompt += f\"\\n{ex}\"\n",
    "\n",
    "    prompt += \"\\n\\nFormat your response as:\\nAssertion: <assertion text>\"\n",
    "\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7b6c84f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_refinement_prompt_comprehensiveness_iter2(assertion_1_text, assertion_2_text, correlation_strength, correlation_value, p_value, diagnosed_issue, specific_hypothesis, example_assertions=None):\n",
    "    prompt = f\"\"\"Your job is to help understand statistical relationships between two binary assertions used to evaluate AI system behavior. Based on a hypothesized relationship between these assertions, your task is to generate new, **refined assertions** that better distinguish between different dimensions of system performance.\n",
    "\n",
    "Assertion Details:\n",
    "A1: {assertion_1_text}  \n",
    "A2: {assertion_2_text}\n",
    "\n",
    "Correlation Analysis:\n",
    "Correlation coefficient: {correlation_value:.3f}  \n",
    "Correlation strength: {correlation_strength}  \n",
    "Statistical significance: p = {p_value:.4g}  \n",
    "\n",
    "Diagnosed issue (general): {diagnosed_issue}\n",
    "Specific hypothesis: {specific_hypothesis}\n",
    "\n",
    "Generate five ideas for refined assertions that separate or clarify the evaluation criteria expressed in A1 and A2. These refinements should help evaluators more clearly distinguish **specific aspects** of output quality.\"\"\"\n",
    "\n",
    "    if example_assertions:\n",
    "            prompt += \"\\n\\nFor example:\"\n",
    "            for ex in example_assertions:\n",
    "                prompt += f\"\\n{ex}\"\n",
    "\n",
    "    prompt += \"\\n\\nFormat your response as:\\nAssertion: <refined assertion text>\"\n",
    "\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b0dca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Manually selected from dict_hypotheses\n",
    "\n",
    "selected_hypotheses = {\n",
    "    \"strong\": \"Assertion 2 is a subset of Assertion 1, as Assertion 1 requires overall factual consistency, which inherently includes the absence of fabricated details covered by Assertion 2, resulting in a strong correlation when both assertions are satisfied.\",\n",
    "    \"weak\": \"The two assertions, A1 and A2, capture overlapping but distinct concepts, where A1 focuses on excluding irrelevant information, while A2 emphasizes the inclusion of necessary context, leading to scenarios where outputs can satisfy one without necessarily satisfying the other.\",\n",
    "    \"inverse\": \"Assertion A1 is a logical negation of Assertion A2, as a sentence free from grammatical errors and awkward phrasing (A1) inherently cannot contain incomplete or structurally deficient elements (A2), creating an inverse relationship.\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8be4a5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Manually selected from matching selected_hypotheses to their best fit diagnosis \n",
    "### (refer to structural validity workflow design doc/ figma) \n",
    "\n",
    "selected_diagnoses = {\n",
    "    \"strong\": \"Each assertion captures redundant properties of system outputs.\",\n",
    "    \"weak\": \"The assertions capture complementary aspects of the property.\",\n",
    "    \"inverse\": \"One assertion is a logical negation of another.\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5e6b37a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_assertions = [\n",
    "    \"Each sentence in the summary accurately conveys a complete thought without grammatical or structural errors.\",\n",
    "    \"The summary only includes key information directly relevant to the article's main claims or events.\",\n",
    "    \"Information in the summary is presented in a logically coherent order, with no contradictory or disjointed transitions.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c1899f77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your job is to help understand statistical relationships between two binary assertions used to evaluate AI system behavior. Based on a hypothesized relationship between these assertions, your task is to generate new, **refined assertions** that better distinguish between different dimensions of system performance.\n",
      "\n",
      "Assertion Details:\n",
      "A1: Each sentence is free from grammatical errors and awkward phrasing.  \n",
      "A2: Contains sentences that are incomplete or lack a clear subject-verb-object structure\n",
      "\n",
      "Correlation Analysis:\n",
      "Correlation coefficient: -0.567  \n",
      "Correlation strength: inverse  \n",
      "Statistical significance: p = 6.712e-27  \n",
      "\n",
      "Diagnosed issue (general): One assertion is a logical negation of another.\n",
      "Specific hypothesis: Assertion A1 is a logical negation of Assertion A2, as a sentence free from grammatical errors and awkward phrasing (A1) inherently cannot contain incomplete or structurally deficient elements (A2), creating an inverse relationship.\n",
      "\n",
      "Generate five ideas for refined assertions that separate or clarify the evaluation criteria expressed in A1 and A2. These refinements should help evaluators more clearly distinguish **specific aspects** of output quality.\n",
      "\n",
      "For example:\n",
      "Each sentence in the summary accurately conveys a complete thought without grammatical or structural errors.\n",
      "The summary only includes key information directly relevant to the article's main claims or events.\n",
      "Information in the summary is presented in a logically coherent order, with no contradictory or disjointed transitions.\n",
      "\n",
      "Format your response as:\n",
      "Assertion: <refined assertion text>\n"
     ]
    }
   ],
   "source": [
    "refinement_prompts = {}\n",
    "\n",
    "for case in correlation_cases:\n",
    "    idx1, idx2 = assertion_pair_indices[case]\n",
    "    a1_label, a2_label = assertion_labels[idx1], assertion_labels[idx2]\n",
    "    \n",
    "    a1_text = get_assertion_text(a1_label)\n",
    "    a2_text = get_assertion_text(a2_label)\n",
    "\n",
    "    r_val = correlation_values[case]\n",
    "    _, p_val = pearsonr(avg_scores_across_models[:, idx1], avg_scores_across_models[:, idx2])\n",
    "\n",
    "    diagnosis = selected_diagnoses[case]\n",
    "    hypothesis = selected_hypotheses[case]\n",
    "    \n",
    "    prompt = build_refinement_prompt_comprehensiveness_iter2( ### change function here\n",
    "        assertion_1_text=a1_text,\n",
    "        assertion_2_text=a2_text,\n",
    "        correlation_strength=case,\n",
    "        correlation_value=corr,\n",
    "        p_value=p_val,\n",
    "        diagnosed_issue=diagnosis,\n",
    "        specific_hypothesis=hypothesis,\n",
    "        example_assertions=example_assertions\n",
    "    )\n",
    "\n",
    "    refinement_prompts[case] = prompt\n",
    "\n",
    "print(refinement_prompts[\"inverse\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07628abb",
   "metadata": {},
   "source": [
    "## 5.2 Run Refinement Prompts - OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "896fb775",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_assertions_to_list(text):\n",
    "    chunks = re.split(r'\\bAssertion\\s*\\d+\\s*:\\s*', text)\n",
    "    \n",
    "    parsed = [chunk.strip() for chunk in chunks if chunk.strip()]\n",
    "    \n",
    "    return parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a722916a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case:  strong\n",
      "Case:  weak\n",
      "Case:  inverse\n"
     ]
    }
   ],
   "source": [
    "dict_assertions = {case: [] for case in correlation_cases}\n",
    "\n",
    "for case in correlation_cases:\n",
    "    print(\"Case: \", case)\n",
    "\n",
    "    idx1, idx2 = assertion_pair_indices[case]\n",
    "    a1_label, a2_label = assertion_labels[idx1], assertion_labels[idx2]\n",
    "    a1_text = get_assertion_text(a1_label)\n",
    "    a2_text = get_assertion_text(a2_label)\n",
    "\n",
    "    prompt = refinement_prompts[case]\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are an expert in designing evaluation criteria for AI behavior analysis. Your job is to create new, precise, and binary assertions.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=0.7,\n",
    "        max_tokens=1000,\n",
    "    )\n",
    "\n",
    "    assertions_text = response.choices[0].message.content.strip()\n",
    "    assertions_list = parse_assertions_to_list(assertions_text)\n",
    "    dict_assertions[case] = assertions_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "10444702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== STRONG ===\n",
      "Hypothesis:  Assertion 2 is a subset of Assertion 1, as Assertion 1 requires overall factual consistency, which inherently includes the absence of fabricated details covered by Assertion 2, resulting in a strong correlation when both assertions are satisfied.\n",
      "Diagnosed Issue:  Each assertion captures redundant properties of system outputs.\n",
      "Old Assertion 1 (Consistency - C4-A1): Consistency measures whether the facts in the summary are consistent with the facts in the original article. COnsider whether the summary does reproduce all facts accurately and does not make up untrue information.\n",
      "Old Assertion 2 (Consistency - C4-A2): The summary includes no fabricated details or misrepresented facts compared to the original article.\n",
      "\n",
      "New Assertion 1: Assertion: The summary accurately reflects the chronological order of events as presented in the original article, ensuring temporal consistency.\n",
      "\n",
      "Assertion: The summary excludes any editorializing or subjective interpretations that were not present in the original article, maintaining objective reporting.\n",
      "\n",
      "Assertion: Each claim made in the summary is substantiated by a specific section or quote from the original article, ensuring traceability of information.\n",
      "\n",
      "Assertion: The summary preserves the original article's tone and intent, refraining from adding unintended bias or emphasis.\n",
      "\n",
      "Assertion: The summary captures and correctly represents quantitative data and figures from the original article, ensuring numerical accuracy.\n",
      "\n",
      "=== WEAK ===\n",
      "Hypothesis:  The two assertions, A1 and A2, capture overlapping but distinct concepts, where A1 focuses on excluding irrelevant information, while A2 emphasizes the inclusion of necessary context, leading to scenarios where outputs can satisfy one without necessarily satisfying the other.\n",
      "Diagnosed Issue:  The assertions capture complementary aspects of the property.\n",
      "Old Assertion 1 (Relevance - C2-A2): Contains no irrelevant or extraneous information unrelated to the article's main points\n",
      "Old Assertion 2 (Relevance - C2-A3): Includes all context necessary for understanding key events or claims\n",
      "\n",
      "New Assertion 1: Assertion: The summary excludes any details or data points that do not directly support the article's main thesis or objectives.\n",
      "\n",
      "Assertion: The summary integrates all relevant background information needed to fully understand the main events or claims discussed in the article.\n",
      "\n",
      "Assertion: Each piece of information included in the summary directly contributes to a clear understanding of the article's primary arguments or findings.\n",
      "\n",
      "Assertion: The summary avoids mentioning tangential topics or anecdotes that do not enhance comprehension of the article's core message.\n",
      "\n",
      "Assertion: The summary ensures that all necessary contextual elements, such as historical background or stakeholder perspectives, are included to provide comprehensive understanding.\n",
      "\n",
      "=== INVERSE ===\n",
      "Hypothesis:  Assertion A1 is a logical negation of Assertion A2, as a sentence free from grammatical errors and awkward phrasing (A1) inherently cannot contain incomplete or structurally deficient elements (A2), creating an inverse relationship.\n",
      "Diagnosed Issue:  One assertion is a logical negation of another.\n",
      "Old Assertion 1 (Fluency - C1-A2): Each sentence is free from grammatical errors and awkward phrasing.\n",
      "Old Assertion 2 (Fluency - C1-A3): Contains sentences that are incomplete or lack a clear subject-verb-object structure\n",
      "\n",
      "New Assertion 1: Assertion: Each sentence in the text demonstrates proper use of tense and subject-verb agreement, avoiding any errors in these specific grammatical areas.\n",
      "\n",
      "Assertion: The text maintains a consistent and logical flow of ideas from one sentence to the next, with clear and purposeful connections between thoughts.\n",
      "\n",
      "Assertion: All sentences in the text are complete, containing a clear subject and predicate without missing essential components.\n",
      "\n",
      "Assertion: The content of each sentence accurately reflects the intended meaning and context, avoiding ambiguity or misleading phrasing.\n",
      "\n",
      "Assertion: Each sentence is free from awkward constructions or overly complex syntax, promoting clarity and ease of understanding for the reader.\n"
     ]
    }
   ],
   "source": [
    "for case in correlation_cases:\n",
    "    print(f\"\\n=== {case.upper()} ===\")\n",
    "    print(\"Hypothesis: \", selected_hypotheses[case])\n",
    "    print(\"Diagnosed Issue: \", selected_diagnoses[case])\n",
    "\n",
    "    idx1, idx2 = assertion_pair_indices[case]\n",
    "    a1_label, a2_label = assertion_labels[idx1], assertion_labels[idx2]\n",
    "    a1_text = get_assertion_text(a1_label)\n",
    "    a2_text = get_assertion_text(a2_label)\n",
    "\n",
    "    print(f\"Old Assertion 1 ({a1_label}): {a1_text}\")\n",
    "    print(f\"Old Assertion 2 ({a2_label}): {a2_text}\\n\")\n",
    "\n",
    "    for i, a in enumerate(dict_assertions.get(case, [])[:5], start=1):\n",
    "        print(f\"New Assertion {i}: {a}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a1eb4d",
   "metadata": {},
   "source": [
    "# Appendix A: Archived Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc23f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def build_hypothesis_prompt_iter1(df, input_col, output_col, \n",
    "#                              assertion_text_1, assertion_text_2,\n",
    "#                              assertion_type_1, assertion_type_2,\n",
    "#                              correlation_strength, correlation_value, p_value,\n",
    "#                              assertion_scores, item_indices, *,\n",
    "#                              include_categories=True):\n",
    "    \n",
    "#     prompt = f\"\"\"Your job is to help understand statistical relationships between two binary assertions used to evaluate AI system behavior.\n",
    "\n",
    "# Assertion Details:\n",
    "# * A1: {assertion_text_1}\n",
    "# * A2: {assertion_text_2}\n",
    "# * Assertion types: {assertion_type_1} and {assertion_type_2}\n",
    "\n",
    "# Correlation Analysis:\n",
    "# * Correlation coefficient: {correlation_value:.3f}\n",
    "# * Correlation strength: {correlation_strength}\n",
    "# * Statistical significance: p = {p_value:.4g}\n",
    "\n",
    "# Based on the following list of Generative AI system inputs and outputs and corresponding assertion values, generate hypotheses for why the assertions exhibit this correlation pattern.\n",
    "# \"\"\"\n",
    "\n",
    "#     # Add the 5 data items\n",
    "#     for idx, row_idx in enumerate(item_indices, 1):\n",
    "#         row = df.iloc[row_idx]\n",
    "#         a1_score, a2_score = assertion_scores[row_idx]\n",
    "#         prompt += f\"\"\"\n",
    "# Item {idx}: \n",
    "# Input: {getattr(row, input_col)}\n",
    "# Output: {getattr(row, output_col)}\n",
    "# Assertion 1: {a1_score:.1f}\n",
    "# Assertion 2: {a2_score:.1f}\n",
    "# \"\"\"\n",
    "\n",
    "#     if include_categories:\n",
    "#         prompt += \"\"\"\n",
    "# Instructions: Return 5 hypotheses for the observed correlation pattern, formatted as \"Hypothesis {#}: {hypothesis statement}\". Consider these categories when generating hypotheses:\n",
    "\n",
    "# Conceptual Relationship Categories:\n",
    "# * Conceptual Independence: The two assertions capture fundamentally different concepts\n",
    "# * Logical Dependency: One assertion is a logical negation, subset, or superset of another\n",
    "# * Information Overlap: The assertions capture similar or redundant information about system behavior\n",
    "\n",
    "# Measurement Sensitivity Categories:\n",
    "# * Threshold Differences: The assertions have different sensitivity thresholds for positive evaluation\n",
    "# * Edge Case Sensitivity: One assertion is more sensitive to edge cases, outliers, or boundary conditions\n",
    "# * Granularity Mismatch: The assertions operate at different levels of detail or specificity\n",
    "\n",
    "# Input-Output Relationship Categories:\n",
    "# * Input vs. Output Focus: One assertion primarily evaluates input characteristics while the other focuses on output quality\n",
    "# * Context Dependency: The assertions respond differently to specific input contexts or domains\n",
    "# * Temporal Sensitivity: One assertion is more sensitive to sequence, timing, or order effects\n",
    "\n",
    "# System Behavior Categories:\n",
    "# * Performance Trade-offs: The assertions represent competing objectives or trade-offs in system performance\n",
    "# * Failure Mode Correlation: The assertions tend to fail together or in opposing patterns under certain conditions\n",
    "\n",
    "# Example hypotheses:\n",
    "# * \"The two assertions capture different concepts with minimal overlap\"\n",
    "# * \"One assertion is a logical negation of another, creating inverse correlation\"\n",
    "# * \"Assertion 1 is more sensitive to edge cases than Assertion 2\"\n",
    "# * \"The assertions have different thresholds, with A1 being more restrictive than A2\"\n",
    "# \"\"\"\n",
    "#     else:\n",
    "#         prompt += \"\"\"\n",
    "# Instructions: Return 5 hypotheses for the observed correlation pattern, formatted as \"Hypothesis {#}: {hypothesis statement}\".\n",
    "# \"\"\"\n",
    "\n",
    "#     return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b053ea30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def build_combined_assertion_prompt_iter1(assertion_1_text,assertion_2_text,correlation_strength,correlation_value,p_value,diagnosed_issue,example_assertions=None):\n",
    "#     prompt = f\"\"\"Your job is to help understand statistical relationships between two binary assertions used to evaluate AI system behavior. Based on a hypothesized relationship between these assertions, your task is to generate new assertions that resolve the identified issues. \n",
    "\n",
    "# Assertion Details:\n",
    "# A1: {assertion_1_text}\n",
    "# A2: {assertion_2_text}\n",
    "\n",
    "# Correlation Analysis:\n",
    "# Correlation coefficient: {correlation_value:.3f}\n",
    "# Correlation strength: {correlation_strength}\n",
    "# Statistical significance: p = {p_value:.4g}\n",
    "# Diagnosed issue: {diagnosed_issue}\n",
    "\n",
    "# Generate five new assertions that combine A1 and A2 while preserving the main evaluation goals. Assertions should be binary statements that can be evaluated for each target system input-output pair.\"\"\"\n",
    "    \n",
    "#     if example_assertions:\n",
    "#         prompt += \"\\n\\nFor example:\"\n",
    "#         for ex in example_assertions:\n",
    "#             prompt += f\"\\n{ex}\"\n",
    "\n",
    "#     prompt += \"\\n\\nFormat your response as:\\nAssertion: <assertion text>\"\n",
    "\n",
    "#     return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06028ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def build_refinement_prompt_completeness_iter1(assertion_1_text, assertion_2_text, correlation_strength, correlation_value, p_value, diagnosed_issue, example_assertions=None):\n",
    "#     prompt = f\"\"\"Your job is to help understand statistical relationships between two binary assertions used to evaluate AI system behavior. Based on a hypothesized relationship between these assertions, your task is to generate new, **refined assertions** that better distinguish between different dimensions of system performance.\n",
    "\n",
    "# Assertion Details:\n",
    "# A1: {assertion_1_text}  \n",
    "# A2: {assertion_2_text}\n",
    "\n",
    "# Correlation Analysis:\n",
    "# Correlation coefficient: {correlation_value:.3f}  \n",
    "# Correlation strength: {correlation_strength}  \n",
    "# Statistical significance: p = {p_value:.4g}  \n",
    "# Diagnosed issue: {diagnosed_issue}\n",
    "\n",
    "# Generate five ideas for refined assertions that separate or clarify the evaluation criteria expressed in A1 and A2. These refinements should help evaluators more clearly distinguish **specific aspects** of output quality.\"\"\"\n",
    "\n",
    "#     if example_assertions:\n",
    "#             prompt += \"\\n\\nFor example:\"\n",
    "#             for ex in example_assertions:\n",
    "#                 prompt += f\"\\n{ex}\"\n",
    "\n",
    "#     prompt += \"\\n\\nFormat your response as:\\nAssertion: <refined assertion text>\"\n",
    "\n",
    "#     return prompt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hypothesaes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
